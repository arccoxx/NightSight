# NightSight v2: Military Night Vision-Inspired Enhancement

**Advanced AI-Powered Night Vision from Standard Cameras**

NightSight v2 is an experimental enhancement system inspired by military night vision technology. It combines depth estimation, object differentiation, and bright outline overlays to create a comprehensive low-light enhancement solution with real-time object tracking and scene-adaptive processing.

## What's New in v2

NightSight v2 introduces military-grade night vision capabilities to standard cameras:

### Core Features

1. **Depth-Based Object Differentiation**
   - Lightweight depth estimation for object separation
   - Depth-aware colored outlines (near objects vs. far objects)
   - Military-style depth visualization overlays

2. **Glowing Edge Outlines**
   - Bright green (or customizable) outlines around objects
   - Multi-scale edge detection (deep learning + traditional)
   - Glowing effect with adjustable intensity
   - Mimics military night vision display

3. **Zero-DCE++ Low-Light Enhancement**
   - Self-supervised curve-based enhancement
   - No paired training data required
   - Adaptive brightness and contrast adjustment
   - Preserves color and details

4. **Real-Time Object Detection & Tracking**
   - YOLOv8n integration for fast detection
   - Multi-object tracking with Kalman filters
   - Trajectory prediction and visualization
   - Glowing bounding boxes with class labels

5. **Super-Resolution & Denoising**
   - ESRGAN-based upscaling (optional)
   - Deep learning denoising for clean images
   - Traditional fallback methods (bilateral, NLM)
   - Noise reduction optimized for low-light

6. **Color Restoration**
   - Approximate color reconstruction from dark scenes
   - Natural color preservation
   - Adaptive white balance

7. **Scene-Adaptive Processing**
   - Automatic lighting condition detection
   - Parameter auto-adjustment based on scene
   - 5 scene classes: very dark, dark, dim, normal, bright
   - Optimal settings for each condition

## Installation

### Install NightSight v2

```bash
# Install base NightSight
pip install -e .

# Install v2 dependencies
pip install ultralytics>=8.0.0

# Optional: Install super-resolution dependencies
# pip install realesrgan
```

### Quick Start

```python
from nightsight.v2.pipeline import NightSightV2Pipeline

# Create v2 pipeline
pipeline = NightSightV2Pipeline(device='cuda')  # or 'cpu'

# Enhance image
enhanced = pipeline.enhance_image('dark_image.jpg', 'enhanced_v2.jpg')

# Process video
pipeline.enhance_video('dark_video.mp4', 'enhanced_v2.mp4')

# Real-time webcam
pipeline.process_webcam(camera_id=0)
```

## Usage Examples

### Command Line Interface

**Process an image:**
```bash
python scripts/inference_v2.py -i dark.jpg -o enhanced.jpg
```

**Process a video:**
```bash
python scripts/inference_v2.py -i dark_video.mp4 -o enhanced_video.mp4
```

**Real-time webcam demo:**
```bash
python scripts/realtime_v2_demo.py --camera 0
```

**Compare v1 vs v2:**
```bash
python scripts/inference_v2.py -i dark.jpg -o comparison.jpg --compare-v1
```

### Python API

**Basic Usage:**
```python
from nightsight.v2 import NightSightV2Pipeline

# Initialize pipeline
pipeline = NightSightV2Pipeline(
    device='cuda',
    use_all_features=True  # Enable all enhancements
)

# Enhance single image
enhanced = pipeline.enhance_image('input.jpg', 'output.jpg')
```

**Customize Modules:**
```python
pipeline = NightSightV2Pipeline(
    device='cuda',
    use_depth=True,           # Depth estimation
    use_zerodce=True,         # Low-light enhancement
    use_edges=True,           # Glowing outlines
    use_detection=True,       # Object detection
    use_tracking=True,        # Multi-object tracking
    use_superres=False,       # Super-resolution (slow)
    use_adaptive=True         # Scene-adaptive processing
)
```

**Get Intermediate Results:**
```python
enhanced, components = pipeline.enhance_image(
    'input.jpg',
    return_components=True
)

# Available components:
# - scene_config: Adaptive configuration
# - zerodce_enhanced: After Zero-DCE++
# - depth_map: Depth estimation
# - edges: Detected edges
# - with_outlines: Image with glowing outlines
# - detections: Object detection results
# - with_detections: Final result with boxes
```

**Video Processing with Tracking:**
```python
# Process video (automatic tracking)
pipeline.enhance_video(
    'input_video.mp4',
    'output_video.mp4',
    show_progress=True
)
```

**Interactive Webcam Demo:**
```python
# Real-time processing with controls
pipeline.process_webcam(
    camera_id=0,
    display_fps=True
)

# Controls during webcam:
# q - Quit
# s - Save screenshot
# 1 - Toggle depth estimation
# 2 - Toggle Zero-DCE++
# 3 - Toggle edge outlines
# 4 - Toggle object detection
# 5 - Toggle object tracking
# 6 - Toggle super-resolution
# 7 - Toggle adaptive processing
```

**Direct Model Access:**
```python
from nightsight.v2 import NightSightV2

# Initialize model
model = NightSightV2(
    device='cuda',
    use_all_features=True
)

# Process image
import numpy as np
image = np.random.rand(480, 640, 3)  # Your image
enhanced = model.forward(image)

# Process video frame with tracking
enhanced, info = model.process_video_frame(frame)
tracks = info['tracks']  # Tracked objects
```

## Architecture

NightSight v2 is built with a modular architecture:

```
nightsight/v2/
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ depth_estimator.py      # Depth estimation network
‚îÇ   ‚îú‚îÄ‚îÄ zerodce_plus.py          # Zero-DCE++ enhancement
‚îÇ   ‚îú‚îÄ‚îÄ edge_outliner.py         # Edge detection & glowing outlines
‚îÇ   ‚îú‚îÄ‚îÄ object_detector.py       # YOLOv8n detection
‚îÇ   ‚îú‚îÄ‚îÄ tracker.py               # Multi-object tracking
‚îÇ   ‚îú‚îÄ‚îÄ super_resolution.py      # SR & denoising
‚îÇ   ‚îî‚îÄ‚îÄ scene_classifier.py      # Adaptive scene classification
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ nightsight_v2.py         # Main v2 model
‚îî‚îÄ‚îÄ pipeline.py                   # High-level pipeline
```

### Processing Pipeline

1. **Scene Analysis** ‚Üí Determine lighting conditions
2. **Zero-DCE++ Enhancement** ‚Üí Brighten dark regions
3. **Depth Estimation** ‚Üí Generate depth map
4. **Edge Detection** ‚Üí Detect object boundaries
5. **Glowing Outlines** ‚Üí Apply depth-colored outlines
6. **Object Detection** ‚Üí Detect and classify objects
7. **Tracking** ‚Üí Track objects across frames
8. **Super-Resolution** (optional) ‚Üí Upscale image
9. **Final Composition** ‚Üí Combine all enhancements

## Module Details

### 1. Depth Estimation
- **Model**: Lightweight MobileNet-style encoder-decoder
- **Output**: Depth map (0=far, 1=near)
- **Use**: Object differentiation and depth-aware outlines
- **Speed**: ~30 FPS on GPU

### 2. Zero-DCE++ Enhancement
- **Method**: Deep curve estimation
- **Training**: Zero-reference (no paired data needed)
- **Output**: Brightened image with preserved details
- **Speed**: ~60 FPS on GPU

### 3. Edge Detection & Outlining
- **Methods**: HED-style deep edges + Canny
- **Effect**: Military night vision-style glowing outlines
- **Colors**: Customizable (default: green)
- **Depth-aware**: Different colors for near/far objects

### 4. Object Detection
- **Model**: YOLOv8n (nano) for speed
- **Classes**: 80 COCO classes
- **Visualization**: Glowing bounding boxes
- **Speed**: ~100 FPS on GPU

### 5. Multi-Object Tracking
- **Method**: Kalman filter + IoU matching
- **Features**:
  - Trajectory history
  - Future prediction
  - Unique IDs per object
- **Visualization**: Tracks with predicted paths

### 6. Super-Resolution
- **Model**: Lightweight ESRGAN variant
- **Scales**: 2x or 4x upsampling
- **Denoising**: Integrated noise reduction
- **Speed**: ~10 FPS on GPU (disabled by default)

### 7. Scene Classification
- **Method**: Statistical + optional ML
- **Classes**: very_dark, dark, dim, normal, bright
- **Output**: Recommended parameters for scene
- **Adaptive**: Auto-adjusts enhancement strength

## Performance

Tested on NVIDIA RTX 3080:

| Mode | Resolution | FPS | Modules |
|------|-----------|-----|---------|
| Fast | 640x480 | 60+ | ZeroDCE + Edges |
| Standard | 640x480 | 30+ | All except SR |
| High Quality | 640x480 | 15+ | All + SR |
| 1080p Standard | 1920x1080 | 15+ | All except SR |

CPU performance (Intel i7):
- Fast mode: ~5 FPS
- Standard mode: ~2 FPS

## Comparison: v1 vs v2

| Feature | v1 | v2 |
|---------|----|----|
| Low-light enhancement | ‚úÖ | ‚úÖ Enhanced |
| Depth estimation | ‚ùå | ‚úÖ |
| Edge outlines | ‚ùå | ‚úÖ |
| Object detection | ‚ùå | ‚úÖ |
| Object tracking | ‚ùå | ‚úÖ |
| Super-resolution | ‚ùå | ‚úÖ |
| Scene-adaptive | ‚ùå | ‚úÖ |
| Military night vision style | ‚ùå | ‚úÖ |
| Real-time video | ‚úÖ | ‚úÖ Improved |
| Speed | Fast | Configurable |

## Training (Optional)

While v2 can work with pretrained models, you can train custom models:

### Train Zero-DCE++
```bash
python scripts/train_zerodce_v2.py \
    --data-dir data/dark_images \
    --epochs 200 \
    --batch-size 8
```

### Train Depth Estimator
```bash
python scripts/train_depth_v2.py \
    --data-dir data/depth_dataset \
    --epochs 100
```

### Train Edge Detector
```bash
python scripts/train_edges_v2.py \
    --data-dir data/bsds500 \
    --epochs 50
```

## Advanced Configuration

### Custom Scene Parameters

```python
# Override automatic scene detection
custom_config = {
    'modules': {
        'zerodce': {'enabled': True, 'strength': 1.0},
        'edge_outliner': {
            'enabled': True,
            'color': (0, 255, 0),  # Green
            'thickness': 3,
            'intensity': 1.0
        },
        'depth_estimator': {'enabled': True},
        'object_detector': {
            'enabled': True,
            'conf_threshold': 0.25
        }
    }
}

enhanced = pipeline.enhance_image('input.jpg', config=custom_config)
```

### Module-Level Control

```python
# Toggle modules on/off
model.set_module_enabled('depth', True)
model.set_module_enabled('edges', False)
model.set_module_enabled('superres', True)
```

## Use Cases

1. **Security & Surveillance**
   - Night-time monitoring
   - Low-light object detection
   - Motion tracking

2. **Robotics**
   - Navigation in dark environments
   - Obstacle detection
   - Path planning

3. **Autonomous Vehicles**
   - Night vision for cars
   - Pedestrian detection
   - Lane tracking

4. **Wildlife Observation**
   - Night-time animal monitoring
   - Non-intrusive observation
   - Species identification

5. **Photography & Content Creation**
   - Night photography enhancement
   - Video production
   - Creative effects

## Limitations

1. **Super-resolution is slow** - Disabled by default, enable only if needed
2. **YOLO detection requires ultralytics** - Install separately
3. **GPU recommended** - CPU mode works but slower
4. **Depth estimation is approximate** - Not metric depth
5. **Object detection in very dark** - May miss small/far objects

## Future Improvements

- [ ] Metric depth estimation (MiDaS integration)
- [ ] Faster super-resolution (SwinIR Lite)
- [ ] Semantic segmentation for better outlines
- [ ] Thermal camera fusion
- [ ] 3D scene reconstruction
- [ ] Mobile/edge device optimization
- [ ] Real-time 4K processing

## Citation

If you use NightSight v2 in your research:

```bibtex
@software{nightsight_v2_2024,
  title={NightSight v2: Military Night Vision-Inspired Enhancement},
  author={NightSight Team},
  year={2024},
  url={https://github.com/nightsight/nightsight}
}
```

## License

MIT License - see LICENSE for details

## Acknowledgments

- YOLOv8 by Ultralytics
- Zero-DCE concept from CVPR 2020
- BSDS500 for edge detection
- Military night vision systems for inspiration

## Support

For issues, questions, or contributions:
- GitHub Issues: https://github.com/nightsight/nightsight/issues
- Documentation: See main README.md for v1 docs

---

**NightSight v2** - See in the dark like never before. üåôüî¶
